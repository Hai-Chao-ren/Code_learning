{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to stream runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aync stream（同步流） 和 async astream（异步流）：流式传输的默认实现，用于流式传输链中的最终输出。\n",
    "# async astream_events 和 async astream_log: 提供一种从链中传输中间步骤和最终输出的方法。\n",
    "# 使应用程序响应更快的关键策略是显示中间进度；即逐个标记地流式传输模型标记的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://localhost:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://localhost:7890\"\n",
    "\n",
    "openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "# print(openai_api_key)\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] =\"https://api.zhizengzeng.com/v1/\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sync stream API(同步流)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| color| of| the| sky| can| vary| depending| on| the| time| of| day| and| weather| conditions|.| During| the| day|,| the| sky| is| typically| blue|,| while| at| sunrise| or| sunset| it| can| appear| orange|,| pink|,| or| purple|.| At| night|,| the| sky| is| usually| dark| blue| or| black|.||"
     ]
    }
   ],
   "source": [
    "###  stream()\n",
    "chunk = []\n",
    "for chunk in model.stream(\"what color is the sky?\"):\n",
    "    chunk.append = chunk\n",
    "    print(chunk.content,end = '|', flush=True)          # flush=True 是指在打印内容后立即刷新输出缓冲区。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "async astream API(异步流)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| color| of| the| sky| can| vary| depending| on| the| time| of| day| and| weather| conditions|.| During| the| day|,| the| sky| is| typically| blue|,| but| it| can| also| appear| gray|,| orange|,| pink|,| or| red| during| sunrise| and| sunset|.| At| night|,| the| sky| is| usually| dark| blue| or| black|.||"
     ]
    }
   ],
   "source": [
    "### Astream()\n",
    "chunks = []\n",
    "async for chunk in model.astream(\"what color is the sky?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='', id='run-629bcffe-31bb-4ada-adf3-52b397da9914')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 打印消息块\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='The color of the', id='run-629bcffe-31bb-4ada-adf3-52b397da9914')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 叠加消息块\n",
    "chunks[0]+chunks[1]+chunks[2]+chunks[3]+chunks[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Why| did| the| par|rot| wear| a| rain|coat|?| Because| he| wanted| to| be| poly|-\"|par|rot|\"-|ic|!||"
     ]
    }
   ],
   "source": [
    "# 使用 StrOutputParser 来解析模型的输出\n",
    "# 从 AIMessageChunk 中提取内容字段，提供模型返回的token\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "async for chunk in chain.astream({\"topic\": \"parrot\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Input Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "{'countries': [{'name': 'France', 'population': 670}]}\n",
      "{'countries': [{'name': 'France', 'population': 670760}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 467}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 467330}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 46733038}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 46733038}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 46733038}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 46733038}, {'name': 'Japan'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 46733038}, {'name': 'Japan', 'population': 126}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 46733038}, {'name': 'Japan', 'population': 126476}]}\n",
      "{'countries': [{'name': 'France', 'population': 67076000}, {'name': 'Spain', 'population': 46733038}, {'name': 'Japan', 'population': 126476461}]}\n"
     ]
    }
   ],
   "source": [
    "### JsonOutputParser()转换\n",
    "#  parser（解析器）对输入流进行操作，将部分 JSON“自动完成”为有效状态。\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")     # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models\n",
    "\n",
    "async for text in chain.astream(\"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"):\n",
    "\n",
    "    print(text,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']|"
     ]
    }
   ],
   "source": [
    "### 附加函数\n",
    "\n",
    "from langchain_core.output_parsers import (JsonOutputParser,)\n",
    "\n",
    "# A function that operates on finalized inputs\n",
    "# rather than on an input_stream\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):                  # isinstance(input, dict)检查\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries,list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "# 附加提取函数，从最终输出的json中提取国家/地区名称\n",
    "chain = model | JsonOutputParser() | _extract_country_names\n",
    "\n",
    "async for text in chain.astream (\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "    \n",
    "    print(text, end=\"|\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France|Spain|Japan|"
     ]
    }
   ],
   "source": [
    "### 修复流式输出 Generator Functions\n",
    "# 使用可以对输入流进行操作的生成器函数来修复流式传输。\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "async def _extract_country_names_streaming(input_stream):\n",
    "    \"\"\"A function that operates on input streams.\"\"\"\n",
    "    country_names_so_far = set()          # 创建空集合                          \n",
    "\n",
    "    # 异步迭代处理输入流中的每个输入对象\n",
    "    async for input in input_stream:\n",
    "        if not isinstance(input, dict):\n",
    "            continue\n",
    "\n",
    "        if \"countries\" not in input:\n",
    "            continue\n",
    "\n",
    "        countries = input[\"countries\"]\n",
    "\n",
    "        if not isinstance(countries, list):\n",
    "            continue\n",
    "\n",
    "        for country in countries:\n",
    "            name = country.get(\"name\")\n",
    "            if not name:\n",
    "                continue\n",
    "            if name not in country_names_so_far:\n",
    "                yield name                                # yield 关键字用于定义生成器函数，暂停函数的执行并返回一个值，稍后可以从暂停的地方继续执行。\n",
    "                country_names_so_far.add(name)\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names_streaming\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-streaming components (非流式组件)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS             # 向量搜索库,快速查找最相似的文档\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(page_content='harrison worked at kensho'),\n",
       "  Document(page_content='harrison likes spicy food')]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### 内置组件流式输出\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 使用 FAISS 进行向量存储：\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\", \"harrison likes spicy food\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "# 数据结构转换\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 对内置组件（retriver）进行流式传输\n",
    "chunks = [chunk for chunk in retriever.stream(\"where did harrison work?\")]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|H|arrison| worked| at| Kens|ho|,| a| trendy| restaurant| known| for| its| fusion| cuisine|.| The| atmosphere| at| Kens|ho| is| always| bustling| with| energy| and| excitement|.| The| menu| at| Kens|ho| features| a| variety| of| unique| dishes| that| perfectly| blend| different| culinary| traditions|.| Customers| at| Kens|ho| always| leave| satisfied| and| eager| to| come| back| for| more|.||"
     ]
    }
   ],
   "source": [
    "\n",
    "### LCEL链流式传输\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        # 返回配置过的检索器对象，该对象使用了 “Docs” 的运行配置。\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in retrieval_chain.stream(\n",
    "    \"Where did harrison work? \" \"Write 3 made up sentences about this place.\"\n",
    "):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Stream Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event Reference（事件参考）\n",
    "略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\llm\\lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "### 查看Chat Model 生成事件\n",
    "events = []\n",
    "async for event in model.astream_events(\"hello\", version=\"v2\"):\n",
    "    events.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chat_model_start',\n",
       "  'data': {'input': 'hello'},\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'run_id': '99132e12-8f8d-4253-938c-caab03655522',\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-3.5-turbo-0125',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '99132e12-8f8d-4253-938c-caab03655522',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-3.5-turbo-0125',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content='', id='run-99132e12-8f8d-4253-938c-caab03655522')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '99132e12-8f8d-4253-938c-caab03655522',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-3.5-turbo-0125',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content='Hello', id='run-99132e12-8f8d-4253-938c-caab03655522')},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chat_model_stream',\n",
       "  'run_id': '99132e12-8f8d-4253-938c-caab03655522',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-3.5-turbo-0125',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content='', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-99132e12-8f8d-4253-938c-caab03655522')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_end',\n",
       "  'data': {'output': AIMessageChunk(content='Hello! How can I assist you today?', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-99132e12-8f8d-4253-938c-caab03655522')},\n",
       "  'run_id': '99132e12-8f8d-4253-938c-caab03655522',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-3.5-turbo-0125',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 解析流式 JSON\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")  # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models\n",
    "\n",
    "events = [\n",
    "    event\n",
    "    async for event in chain.astream_events(\n",
    "        \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "        'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "        \"Each country should have the key `name` and `population`\",\n",
    "        version=\"v2\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chain_start',\n",
       "  'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'},\n",
       "  'name': 'RunnableSequence',\n",
       "  'tags': [],\n",
       "  'run_id': '3bf53f16-dfe1-499b-8d19-29c54d12ac58',\n",
       "  'metadata': {},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_start',\n",
       "  'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`')]]}},\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'run_id': 'd0141f4c-0cc8-4670-8b30-cd0680a4cbe0',\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-3.5-turbo-0125',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'parent_ids': ['3bf53f16-dfe1-499b-8d19-29c54d12ac58']},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'data': {'chunk': AIMessageChunk(content='', id='run-d0141f4c-0cc8-4670-8b30-cd0680a4cbe0')},\n",
       "  'run_id': 'd0141f4c-0cc8-4670-8b30-cd0680a4cbe0',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-3.5-turbo-0125',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'parent_ids': ['3bf53f16-dfe1-499b-8d19-29c54d12ac58']}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: '{\\n'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: '   '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'countries'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' [\\n'\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '       '\n",
      "Chat model chunk: ' {\\n'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: '           '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'name'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' \"'\n",
      "Parser chunk: {'countries': [{'name': ''}]}\n",
      "Chat model chunk: 'France'\n",
      "Parser chunk: {'countries': [{'name': 'France'}]}\n",
      "Chat model chunk: '\",\\n'\n",
      "Chat model chunk: '           '\n",
      "Chat model chunk: ' \"'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### 获取stream events输出\n",
    "# take output the stream events from the model and the parser\n",
    "\n",
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    version=\"v2\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    \n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "        \n",
    "    num_events += 1\n",
    "\n",
    "    # 截断（Truncate）\n",
    "    if num_events > 30:\n",
    "        # Truncate the output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_parser_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'my_parser', 'tags': ['seq:step:2'], 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'metadata': {}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': []}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{}]}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': ''}]}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France'}]}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 652}]}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 652735}]}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 65273511}]}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 65273511}, {}]}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "{'event': 'on_parser_stream', 'run_id': '9c115fc6-bd04-4061-9979-adf7510c584a', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 65273511}, {'name': ''}]}}, 'parent_ids': ['8e3a1d60-ee00-4a97-b3ca-5d8b13314f76']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "### 通过组件名称(Name)过滤\n",
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}                    # with_config()配置参数\n",
    ")\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    version=\"v2\",\n",
    "\n",
    "    # 指定只包括名为 \"my_parser\" 的处理器生成的事件\n",
    "    include_names=[\"my_parser\"],\n",
    "):\n",
    "    print(event)\n",
    "    \n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chat_model_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'model', 'tags': ['seq:step:1'], 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='{\\n', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='   ', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' \"', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='countries', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\":', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' [\\n', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='       ', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' {\\n', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='           ', id='run-c8dcc258-e9ca-4e63-8603-dc08a4c2d846')}, 'run_id': 'c8dcc258-e9ca-4e63-8603-dc08a4c2d846', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e9bc3aa1-3533-4189-9ca0-914a1168d4b3']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "### 通过组件类型(Type)过滤\n",
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`',\n",
    "    version=\"v2\",\n",
    "\n",
    "    # 指定包括\"chat_model\"特定类型的事件\n",
    "    include_types=[\"chat_model\"],\n",
    "):\n",
    "    print(event)\n",
    "\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'RunnableSequence', 'tags': ['my_chain'], 'run_id': '467c9991-f791-414a-9b94-f233bbfab9fc', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`')]]}}, 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'run_id': 'e407887d-5355-49be-b3aa-c1f1230ead57', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', id='run-e407887d-5355-49be-b3aa-c1f1230ead57')}, 'run_id': 'e407887d-5355-49be-b3aa-c1f1230ead57', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "{'event': 'on_parser_start', 'data': {}, 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'run_id': '0c438ff5-6b79-4572-95bf-118572229ef3', 'metadata': {}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='{\\n', id='run-e407887d-5355-49be-b3aa-c1f1230ead57')}, 'run_id': 'e407887d-5355-49be-b3aa-c1f1230ead57', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "{'event': 'on_parser_stream', 'run_id': '0c438ff5-6b79-4572-95bf-118572229ef3', 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'metadata': {}, 'data': {'chunk': {}}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "{'event': 'on_chain_stream', 'run_id': '467c9991-f791-414a-9b94-f233bbfab9fc', 'name': 'RunnableSequence', 'tags': ['my_chain'], 'metadata': {}, 'data': {'chunk': {}}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='   ', id='run-e407887d-5355-49be-b3aa-c1f1230ead57')}, 'run_id': 'e407887d-5355-49be-b3aa-c1f1230ead57', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' \"', id='run-e407887d-5355-49be-b3aa-c1f1230ead57')}, 'run_id': 'e407887d-5355-49be-b3aa-c1f1230ead57', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='countries', id='run-e407887d-5355-49be-b3aa-c1f1230ead57')}, 'run_id': 'e407887d-5355-49be-b3aa-c1f1230ead57', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\":', id='run-e407887d-5355-49be-b3aa-c1f1230ead57')}, 'run_id': 'e407887d-5355-49be-b3aa-c1f1230ead57', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo-0125', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['467c9991-f791-414a-9b94-f233bbfab9fc']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "### 通过组件标签（Tag）过滤\n",
    "\n",
    "chain = (model | JsonOutputParser()).with_config({\"tags\": [\"my_chain\"]})\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`',\n",
    "    version=\"v2\",\n",
    "\n",
    "    # 指定包括\"my_chain\"特定标签的事件\n",
    "    include_tags=[\"my_chain\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-streaming components （非流式组件）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that does not support streaming.\n",
    "# It operates on the finalizes inputs rather than\n",
    "# operating on the input stream.\n",
    "\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser() | _extract_country_names\n",
    ")     # This parser only works with OpenAI right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']\n"
     ]
    }
   ],
   "source": [
    "# astream 无法正常工作，因为 _extract_country_names 不适用于streams。\n",
    "\n",
    "async for chunk in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    print(chunk, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: '{\\n'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: ' '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'countries'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' [\\n'\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '   '\n",
      "Chat model chunk: ' {\\n'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: '     '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'name'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' \"'\n",
      "Parser chunk: {'countries': [{'name': ''}]}\n",
      "Chat model chunk: 'France'\n",
      "Parser chunk: {'countries': [{'name': 'France'}]}\n",
      "Chat model chunk: '\",\\n'\n",
      "Chat model chunk: '     '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'population'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' '\n",
      "Chat model chunk: '670'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "###  astream_events流式输出\n",
    "\n",
    "num_events = 0\n",
    "\n",
    "# 通过 astream_events 我们仍然可以看到来自模型和解析器的 streaming output。\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    version=\"v2\",\n",
    "):\n",
    "    \n",
    "    kind = event[\"event\"]\n",
    "\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "\n",
    "    num_events += 1\n",
    "\n",
    "    if num_events > 30:\n",
    "        # Truncate the output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propagating Callbacks（传播回调）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'bad_tool', 'tags': [], 'run_id': '06872639-06c9-4e30-8172-fec13dfa5bb7', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': '0f492353-c025-41ce-84dd-ae1419fbb61f', 'metadata': {}, 'parent_ids': ['06872639-06c9-4e30-8172-fec13dfa5bb7']}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': '0f492353-c025-41ce-84dd-ae1419fbb61f', 'name': 'reverse_word', 'tags': [], 'metadata': {}, 'parent_ids': ['06872639-06c9-4e30-8172-fec13dfa5bb7']}\n",
      "{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': '06872639-06c9-4e30-8172-fec13dfa5bb7', 'name': 'bad_tool', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "# 如果在工具中使用调用可运行对象，则需要将回调传播到可运行对象；否则，不会生成任何流事件。\n",
    "# 当使用 RunnableLambdas 或 @chain 装饰器时，回调会在幕后自动传播。\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# 反转字符串\n",
    "def reverse_word(word: str):\n",
    "    return word[::-1]           \n",
    "\n",
    "# RunnableLambda() 将该函数包装成可运行对象，使其能够在处理流中被调用和处理\n",
    "reverse_word = RunnableLambda(reverse_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 错误 propagate callbacks（传播回调）\n",
    "@tool\n",
    "def bad_tool(word: str):\n",
    "    \"\"\"Custom tool that doesn't propagate callbacks.\"\"\"\n",
    "    return reverse_word.invoke(word)\n",
    "\n",
    "async for event in bad_tool.astream_events(\"hello\", version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'correct_tool', 'tags': [], 'run_id': 'cbad434a-3f2f-4087-b5ed-0ed193a44133', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': '5e5edbab-cfc6-4324-8b79-779a9432ee87', 'metadata': {}, 'parent_ids': ['cbad434a-3f2f-4087-b5ed-0ed193a44133']}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': '5e5edbab-cfc6-4324-8b79-779a9432ee87', 'name': 'reverse_word', 'tags': [], 'metadata': {}, 'parent_ids': ['cbad434a-3f2f-4087-b5ed-0ed193a44133']}\n",
      "{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': 'cbad434a-3f2f-4087-b5ed-0ed193a44133', 'name': 'correct_tool', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "### 正确 propagate callbacks（传播回调）\n",
    "# 从reverse_word runnable 获取事件。\n",
    "@tool\n",
    "def correct_tool(word:str,callbacks):                       # callbacks（回调函数的集合或字典）\n",
    "    \"\"\"A tool that correctly propagates callbacks.\"\"\"\n",
    "    return reverse_word.invoke(word,{\"callbacks\":callbacks})\n",
    "\n",
    "async for event in correct_tool.astream_events(\"hello\", version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '270f416e-83e2-4a93-af98-3169097068b9', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_stream', 'run_id': '270f416e-83e2-4a93-af98-3169097068b9', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'chunk': '43214321'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '270f416e-83e2-4a93-af98-3169097068b9', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "### 调用Runnable\n",
    "# 从 Runnable Lambda 或 @chains 中调用 Runnable，则callbacks将自动传递\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda      #RunnableLambda类用于创建可调用的异步对象。\n",
    "\n",
    "async def reverse_and_double(word: str):\n",
    "    return await reverse_word.ainvoke(word) * 2\n",
    "\n",
    "reverse_and_double = RunnableLambda(reverse_and_double)\n",
    "\n",
    "await reverse_and_double.ainvoke(\"1234\")                 # ainvoke()方法异步调用函数\n",
    "\n",
    "async for event in reverse_and_double.astream_events(\"1234\", version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': 'ecea49f6-e018-4642-9ad3-8b663f337690', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_stream', 'run_id': 'ecea49f6-e018-4642-9ad3-8b663f337690', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'chunk': '43214321'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': 'ecea49f6-e018-4642-9ad3-8b663f337690', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "### 使用@chain装饰器：\n",
    "\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain     \n",
    "# 将 reverse_and_double 函数包装成一个可链式调用的对象，意味着可以在该函数的基础上连续调用其他方法或函数。\n",
    "async def reverse_and_double(word: str):\n",
    "    return await reverse_word.ainvoke(word) * 2\n",
    "\n",
    "await reverse_and_double.ainvoke(\"1234\")\n",
    "\n",
    "async for event in reverse_and_double.astream_events(\"1234\", version=\"v2\"):\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
