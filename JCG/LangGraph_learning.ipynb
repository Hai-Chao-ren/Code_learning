{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph quick start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "apikey=os.environ[\"OPENAI_API\"] \n",
    "os.environ[\"http_proxy\"] = \"http://localhost:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://localhost:7890\"\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] =\"https://api.zhizengzeng.com/v1/\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",api_key=apikey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't interrupt the tools , the snapshot.next will be action !  it will use the web to search the tool_arg_query! (langgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_sI0ZPFymha3lpk0h9kseZ0hv)\n",
      " Call ID: call_sI0ZPFymha3lpk0h9kseZ0hv\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_sI0ZPFymha3lpk0h9kseZ0hv)\n",
      " Call ID: call_sI0ZPFymha3lpk0h9kseZ0hv\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_id :call_sI0ZPFymha3lpk0h9kseZ0hv\n",
      "messages_id :run-28b0d690-cc3b-487e-83c2-2f4a330fc915-0\n"
     ]
    }
   ],
   "source": [
    "print(f\"tool_id :{existing_message.tool_calls[0]['id']}\")\n",
    "print(f'messages_id :{existing_message.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need't to intercede, we can pass None into the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "# events = graph.stream(None, config, stream_mode=\"values\")\n",
    "# for event in events:\n",
    "#     if \"messages\" in event:\n",
    "#         event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to intercede ,we can  provide the correct the response in the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.messages import ToolMessage\n",
    "answer = (\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs.\"\n",
    ")\n",
    "new_messages = [\n",
    "    # The LLM API expects some ToolMessage to match its tool call. We'll satisfy that here.\n",
    "    ToolMessage(content=answer, tool_call_id=existing_message.tool_calls[0][\"id\"]),\n",
    "    # And then directly \"put words in the LLM's mouth\" by populating its response.\n",
    "    AIMessage(content=answer),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library for building stateful, multi-actor applications with LLMs.\n"
     ]
    }
   ],
   "source": [
    "new_messages[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'thread_ts': '1ef3df46-0b06-650e-8003-d2a519326452'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "graph.update_state(\n",
    "    # Which state to update\n",
    "    config,\n",
    "    # The updated values to provide. The messages in our `State` are \"append-only\", meaning this will be appended\n",
    "    # to the existing state. We will review how to update existing messages in the next section!\n",
    "    {\"messages\": new_messages},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Last 2 messages;\n",
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='d7bcbda0-fd60-447f-b311-3b8a974e9678', tool_call_id='call_sI0ZPFymha3lpk0h9kseZ0hv'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='7d725dbe-bfdd-4953-ad6e-b79d2aaeb1e7')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values[\"messages\"][-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace the existing messages use the same message id ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_uf4L9qwskuqEfUwaGMuKQGiJ)\n",
      " Call ID: call_uf4L9qwskuqEfUwaGMuKQGiJ\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# first we create another thread \n",
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}  # we'll use thread_id = 2 here\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Message ID run-679dab8a-cd68-40c7-9613-666863d938b6-0\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': 'call_uf4L9qwskuqEfUwaGMuKQGiJ'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original\")\n",
    "print(\"Message ID\", existing_message.id)\n",
    "print(existing_message.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_uf4L9qwskuqEfUwaGMuKQGiJ)\n",
      " Call ID: call_uf4L9qwskuqEfUwaGMuKQGiJ\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "new_tool_call[\"args\"][\"query\"] = \"LangGraph human-in-the-loop workflow\"\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    # Important! The ID is how LangGraph knows to REPLACE the message in the state rather than APPEND this messages\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "print(new_message.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph human-in-the-loop workflow'}, 'id': 'call_uf4L9qwskuqEfUwaGMuKQGiJ'}\n",
      "Message ID run-679dab8a-cd68-40c7-9613-666863d938b6-0\n"
     ]
    }
   ],
   "source": [
    "print(\"Updated\")\n",
    "print(new_message.tool_calls[0])\n",
    "print(\"Message ID\", new_message.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tool calls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph human-in-the-loop workflow'},\n",
       "  'id': 'call_uf4L9qwskuqEfUwaGMuKQGiJ'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config, {\"messages\": [new_message]})\n",
    "\n",
    "print(\"\\n\\nTool calls\")\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resume the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://github.com/langchain-ai/langgraph/blob/main/examples/human-in-the-loop.ipynb\", \"content\": \"Build resilient language agents as graphs. Contribute to langchain-ai/langgraph development by creating an account on GitHub.\"}, {\"url\": \"https://blog.langchain.dev/human-in-the-loop-with-opengpts-and-langgraph/\", \"content\": \"To do this we can model the interaction between the actors as happening across multiple discrete steps, when one actor hands off work to another actor, that results in the scheduling of the next step of the computation, and so on, until no more actors hand off work to others, and we\\u2019ve reached the final result.\\n And just as a human team needs more coordination than one person working by themselves, an application with multiple actors needs a coordination layer to\\nMulti-step\\nAs each actor hands off work to another (eg. an LLM prompt asking a search tool for results on a query) we need to make sense of the back-and-forth between multiple actors \\u2013 what order does it happen in, how many times is each actor called, etc. In OpenGPTs we\\u2019ve implemented this mode for Tool Confirmation \\u2013 when this mode is turned on, before any tool is called the application will pause and ask for confirmation, at which point the user can, again\\nWhere to find this\\nYou can go here to demo OpenGPTs and here to fork it.\\n From there the user can choose to\\nAuthorize\\nA 2nd control mode is Authorize, where the user defines ahead of time that they want the application to hand off control to them every time a particular actor is about to be called. Interrupt\\nThe first mode, Interrupt, is the simplest form of control \\u2013 the user is looking at streaming output of the application as it is produced, and manually interrupts it when he sees fit.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I found some information on LangGraph related to a human-in-the-loop workflow. Here are a couple of resources for you to explore:\n",
      "\n",
      "1. [LangGraph on GitHub - Human-in-the-Loop Example](https://github.com/langchain-ai/langgraph/blob/main/examples/human-in-the-loop.ipynb): This resource allows you to build resilient language agents as graphs. You can contribute to LangGraph's development by creating an account on GitHub.\n",
      "\n",
      "2. [Blog Post on Human-in-the-Loop with OpenGPTs and LangGraph](https://blog.langchain.dev/human-in-the-loop-with-opengpts-and-langgraph/): The blog post discusses modeling interactions between actors across multiple discrete steps, the coordination layer needed for applications with multiple actors, and various control modes like Tool Confirmation, Authorize, and Interrupt.\n",
      "\n",
      "These resources should provide you with more insights into LangGraph and its human-in-the-loop workflow.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the model has answered the follow-up questions according to the modified message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"Remember what I'm learning about?\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember what I'm learning about?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You are learning about LangGraph, specifically focusing on its human-in-the-loop workflow. If you have any specific questions or need further information on this topic, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
