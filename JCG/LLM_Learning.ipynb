{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acba41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://localhost:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://localhost:7890\"\n",
    "api_key = \"sk-zk224a777126590fa5988d720e1c413bd6866854f68d0768\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "BASE_URL = \"https://api.zhizengzeng.com/v1\"\n",
    "llm = ChatOpenAI(api_key=api_key,model=\"gpt-3.5-turbo\",base_url=BASE_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9cc4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "tools = [Add, Multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a441f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for chunk in llm.stream(\"what color is the sky?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://localhost:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://localhost:7890\"\n",
    "api_key = \"sk-zk224a777126590fa5988d720e1c413bd6866854f68d0768\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "BASE_URL = \"https://api.zhizengzeng.com/v1\"\n",
    "model = ChatOpenAI(api_key=api_key,model=\"gpt-3.5-turbo\",base_url=BASE_URL)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Write out the following equation using algebraic symbols then solve it. Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\",\n",
    "        ),\n",
    "        (\"human\", \"{equation_statement}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "runnable = (\n",
    "    {\"equation_statement\": RunnablePassthrough()} | prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://localhost:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://localhost:7890\"\n",
    "api_key = \"sk-zk224a777126590fa5988d720e1c413bd6866854f68d0768\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "BASE_URL = \"https://api.zhizengzeng.com/v1\"\n",
    "\n",
    "model = ChatOpenAI(api_key = api_key ,model=\"gpt-3.5-turbo\",base_url=BASE_URL)\n",
    "\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a92b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "    \n",
    "chain1 = prompt | model\n",
    "\n",
    "length_function = RunnableLambda(length_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe50ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6af661",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"a\":itemgetter(\"foo\") | length_function ,\n",
    "        \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "chain.invoke({\"foo\": \"bar\", \"bar\": \"gah\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d2062",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3836769d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a051330f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0a421b",
   "metadata": {},
   "source": [
    "### messages history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fce002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://localhost:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://localhost:7890\"\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "BASE_URL = \"https://api.zhizengzeng.com/v1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025b559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c6624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3259c8c",
   "metadata": {},
   "source": [
    "# the simplest example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96961ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define get session history function\n",
    "\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    print(SQLChatMessageHistory(session_id, \"sqlite:///memory.db\"))\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5967185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_with_history = RunnableWithMessageHistory(\n",
    "    llm,\n",
    "    get_session_history = get_session_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e056fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 7dbbf6d4-e40c-4ec4-8ab1-2b7200db713f not found for run 97b2255f-3307-4e13-a022-13530db2bf98. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, JIN! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 11, 'total_tokens': 23}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-97b2255f-3307-4e13-a022-13530db2bf98-0', usage_metadata={'input_tokens': 11, 'output_tokens': 12, 'total_tokens': 23})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    [HumanMessage(content=\"Hi I'm JIN\")],\n",
    "    config={\"configurable\":{\"session_id\":\"1\"}} # like thread\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6113019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run ec24e921-9549-434b-a0df-fa19cbb1781f not found for run adf341d5-a4a7-4c13-95cf-8672affb1dff. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi I'm JIN\n",
      "AI: Hello, JIN! How can I assist you today?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is JIN. How can I help you further?', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 35, 'total_tokens': 48}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-adf341d5-a4a7-4c13-95cf-8672affb1dff-0', usage_metadata={'input_tokens': 35, 'output_tokens': 13, 'total_tokens': 48})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    [HumanMessage(content=\"what's my name\")],\n",
    "    config={\"configurable\":{\"session_id\":\"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80698275",
   "metadata": {},
   "source": [
    "### runnable  use chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d52c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're an assistant who speaks in {language}. Respond in 20 words or fewer\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable = prompt | llm\n",
    "# we must set input/output key up\n",
    "runnable_with_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c396f13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 87f12f12-398c-4402-a5d1-9553dc5a1dc2 not found for run 925e8fcb-8883-4c3a-aec8-f30e2444bfd6. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao Bob! Come posso aiutarti oggi?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 30, 'total_tokens': 40}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-350d1bdb-66fd-4cb9-b3f5-b3ce9fec730a-0', usage_metadata={'input_tokens': 30, 'output_tokens': 10, 'total_tokens': 40})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    {\"language\": \"italian\", \"input\": \"hi im bob!\"},\n",
    "    config={\"configurable\": {\"session_id\": \"2\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9346916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run c9c86bc6-7861-49f8-814d-526826574da9 not found for run 64e127c9-4432-459c-9d91-3b8d65f1f8bd. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi im bob!\n",
      "AI: Ciao Bob! Come posso aiutarti oggi?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Il tuo nome è Bob!', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 53, 'total_tokens': 59}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-c938fbfc-e14c-4ef3-9869-8e31826def90-0', usage_metadata={'input_tokens': 53, 'output_tokens': 6, 'total_tokens': 59})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    {\"language\": \"italian\", \"input\": \"whats my name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"2\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a621cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain =RunnableParallel({\"output_message\":llm})\n",
    " \n",
    "\n",
    "runnable_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    output_messages_key=\"output_message\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42614aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 0238ab54-54e1-4edf-a40c-b116338141fc not found for run 9b160302-8f84-4645-ace1-dddd0cacbd14. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi - im bob!\n",
      "AI: Hi Bob! How can I assist you today?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_message': AIMessage(content='Hi again, Bob! What would you like to chat about today?', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 35, 'total_tokens': 49}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-3274e6a8-2925-49c8-bf6c-c32819ac78c1-0', usage_metadata={'input_tokens': 35, 'output_tokens': 14, 'total_tokens': 49})}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "     [HumanMessage(content=\"hi - im bob!\")],\n",
    "    config={\"configurable\": {\"session_id\": \"4\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45f706a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# because the input is a dict , we must use itemgetter to align a key \n",
    "\n",
    "runnable_with_history = RunnableWithMessageHistory(\n",
    "    itemgetter(\"input_messages\") | llm,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input_messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ab657ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 2168548c-fdfe-469d-a11d-9df0bc7de7aa not found for run 98bc5d1a-919f-4fe9-a9c3-1b70ff243a32. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-bd58b2a1-d211-4b1a-bf2b-f87fb0c07a72-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "runnable_with_history.invoke(\n",
    "    {\"input_messages\": [HumanMessage(content=\"hi - im bob!\")]},\n",
    "    config={\"configurable\": {\"session_id\": \"5\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
